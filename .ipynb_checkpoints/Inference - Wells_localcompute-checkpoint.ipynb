{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4yvyzdtTw1_O",
   "metadata": {
    "id": "4yvyzdtTw1_O"
   },
   "source": [
    "# Necessary Steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "s86UT7CbZ7u6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 97321,
     "status": "ok",
     "timestamp": 1737461825209,
     "user": {
      "displayName": "ICTD IITD",
      "userId": "11419946949516230456"
     },
     "user_tz": -330
    },
    "id": "s86UT7CbZ7u6",
    "outputId": "fe75cf75-cb99-46cf-d320-5c9088005e5f"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "Mk8wo4294sqE",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3472,
     "status": "ok",
     "timestamp": 1737461828677,
     "user": {
      "displayName": "ICTD IITD",
      "userId": "11419946949516230456"
     },
     "user_tz": -330
    },
    "id": "Mk8wo4294sqE",
    "outputId": "623378b3-2087-400a-f831-6631c74d539f"
   },
   "outputs": [],
   "source": [
    "#!pip install -U ultralytics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "lw8ZKR4_4sic",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10375,
     "status": "ok",
     "timestamp": 1737461839049,
     "user": {
      "displayName": "ICTD IITD",
      "userId": "11419946949516230456"
     },
     "user_tz": -330
    },
    "id": "lw8ZKR4_4sic",
    "outputId": "4bb4ac2d-62af-404c-8645-5e617cc777e4"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import shutil\n",
    "from random import choice\n",
    "import re\n",
    "import csv\n",
    "import pandas as pd\n",
    "import glob\n",
    "import math\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import shape\n",
    "from shapely.geometry import Polygon\n",
    "from ultralytics import YOLO\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "uhelOwSUaNUO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2119,
     "status": "ok",
     "timestamp": 1737461841166,
     "user": {
      "displayName": "ICTD IITD",
      "userId": "11419946949516230456"
     },
     "user_tz": -330
    },
    "id": "uhelOwSUaNUO",
    "outputId": "c3b2be60-77b3-4a54-8196-f9651fb7ff3d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/core-stack/Documents/Ponds\n"
     ]
    }
   ],
   "source": [
    "cd /home/core-stack/Documents/Ponds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "V4A5YTpVaVsM",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1737461841167,
     "user": {
      "displayName": "ICTD IITD",
      "userId": "11419946949516230456"
     },
     "user_tz": -330
    },
    "id": "V4A5YTpVaVsM",
    "outputId": "d9722ca8-5ca4-4c64-a53c-6819914dfc7d"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/core-stack/Documents/Ponds'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd = os.getcwd()\n",
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "RWtC0gO4wEP2",
   "metadata": {
    "id": "RWtC0gO4wEP2"
   },
   "source": [
    "# Download Data for Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "addc33bd-6adb-4487-b73a-9efad95a5ebc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/core-stack/Documents/Ponds'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0ae05a5-25bb-4a4b-acfa-357c17c7730a",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file(\"Shapefiles/Masalia_mws.geojson\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c2ff6f4f-ed13-493c-8bef-50f11841ed11",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'box' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m minx, miny, maxx, maxy \u001b[38;5;241m=\u001b[39m gdf\u001b[38;5;241m.\u001b[39mtotal_bounds\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Create a bounding box polygon\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m bounding_box \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39mGeoDataFrame(geometry\u001b[38;5;241m=\u001b[39m[box(minx, miny, maxx, maxy)], crs\u001b[38;5;241m=\u001b[39mgdf\u001b[38;5;241m.\u001b[39mcrs)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Plot the geometry and the updated bounding box\u001b[39;00m\n\u001b[1;32m      8\u001b[0m fig, ax \u001b[38;5;241m=\u001b[39m plt\u001b[38;5;241m.\u001b[39msubplots(figsize\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m10\u001b[39m, \u001b[38;5;241m6\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'box' is not defined"
     ]
    }
   ],
   "source": [
    "# Compute the bounding box\n",
    "minx, miny, maxx, maxy = gdf.total_bounds\n",
    "\n",
    "# Create a bounding box polygon\n",
    "bounding_box = gpd.GeoDataFrame(geometry=[box(minx, miny, maxx, maxy)], crs=gdf.crs)\n",
    "\n",
    "# Plot the geometry and the updated bounding box\n",
    "fig, ax = plt.subplots(figsize=(10, 6))\n",
    "gdf.plot(ax=ax, color=\"blue\", alpha=0.5, edgecolor=\"black\")\n",
    "bounding_box.plot(ax=ax, edgecolor=\"red\", facecolor=\"none\", linewidth=2)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "890a8c04-0bee-4bc1-8949-8741010f8f5f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6099c26-6102-4e84-b60f-8b3da0a9fcda",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d5ade6a-3ce9-4dd3-8f31-cede3ec43caf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "q-FEeBI3wMdD",
   "metadata": {
    "id": "q-FEeBI3wMdD"
   },
   "source": [
    "Give coordinated of the bounding box drawn on GEE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "TFwJ3YnJwJZK",
   "metadata": {
    "id": "TFwJ3YnJwJZK"
   },
   "outputs": [],
   "source": [
    "#coords for the bounding box (boipariguda)\n",
    "topLeft = [82.07347488402685,18.57110542069261]\n",
    "topRight = [82.60081863402685,18.57110542069261]\n",
    "bottomRight = [82.60081863402685,18.9572939770273]\n",
    "bottomLeft = [82.07347488402685,18.9572939770273]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oFaaB2enwd1S",
   "metadata": {
    "id": "oFaaB2enwd1S"
   },
   "source": [
    "Zoom Level and folder name, where the output (image tiles) will be saved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "gBe0gXYgwct7",
   "metadata": {
    "id": "gBe0gXYgwct7"
   },
   "outputs": [],
   "source": [
    "zoom_level = 18      # Zoom level\n",
    "output_folder = \"/content/drive/MyDrive/Pond/Data_Download/Final/Zoom18/Boipariguda\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6PUmTAcbwJIq",
   "metadata": {
    "id": "6PUmTAcbwJIq"
   },
   "outputs": [],
   "source": [
    "def deg2num(lat_deg, lon_deg, zoom):\n",
    "    lat_rad = math.radians(lat_deg)\n",
    "    n = 2.0 ** zoom\n",
    "    xtile = int((lon_deg + 180.0) / 360.0 * n)\n",
    "    ytile = int((1.0 - math.log(math.tan(lat_rad) + (1 / math.cos(lat_rad))) / math.pi) / 2.0 * n)\n",
    "    return (xtile, ytile)\n",
    "\n",
    "def getCoords(zoomLevel):\n",
    "    topleft = deg2num(topLeft[1], topLeft[0], zoomLevel)  # (c,b)\n",
    "    topright = deg2num(topRight[1], topRight[0], zoomLevel)  # (a,b)\n",
    "    bottomright = deg2num(bottomRight[1], bottomRight[0], zoomLevel)  # (a,d)\n",
    "    bottomleft = deg2num(bottomLeft[1], bottomLeft[0], zoomLevel)  # (c,d)\n",
    "    xmin = min(topleft[0], topright[0], bottomleft[0], bottomright[0])\n",
    "    xmax = max(topleft[0], topright[0], bottomleft[0], bottomright[0])\n",
    "    ymin = min(topleft[1], topright[1], bottomleft[1], bottomright[1])\n",
    "    ymax = max(topleft[1], topright[1], bottomleft[1], bottomright[1])\n",
    "    return (xmin, xmax, ymin, ymax)\n",
    "\n",
    "def download_map_tiles(base_url, output_folder, zoom_level, scale):\n",
    "    # Ensure output folder exists\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Get start time\n",
    "    start_time = time.time()\n",
    "\n",
    "    # Iterate over each tile within the specified range\n",
    "    xmin, xmax, ymin, ymax = getCoords(zoom_level)\n",
    "    for x in range(xmin, xmax + 1):\n",
    "        for y in range(ymin, ymax + 1):\n",
    "            # Construct the URL for the current tile with scale=3 for 640x640\n",
    "            tile_url = f\"{base_url}&x={x}&y={y}&z={zoom_level}&scale={scale}\"\n",
    "            print(tile_url)\n",
    "            try:\n",
    "                # Send HTTP GET request to fetch the tile\n",
    "                response = requests.get(tile_url)\n",
    "\n",
    "                # Check if request was successful (status code 200)\n",
    "                if response.status_code == 200:\n",
    "                    # Save the tile image to a file in the output folder\n",
    "                    filename = f\"tile_{zoom_level}_{x}_{y}.png\"\n",
    "                    filepath = os.path.join(output_folder, filename)\n",
    "                    with open(filepath, \"wb\") as f:\n",
    "                        f.write(response.content)\n",
    "                    print(f\"Downloaded: {filename}\")\n",
    "                else:\n",
    "                    print(f\"Failed to download tile ({x}, {y}), HTTP status code: {response.status_code}\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error downloading tile ({x}, {y}): {e}\")\n",
    "\n",
    "    # Get end time\n",
    "    end_time = time.time()\n",
    "\n",
    "    # Print the total execution time\n",
    "    print(f\"Total time taken: {end_time - start_time} seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "pNtTiywlwVYC",
   "metadata": {
    "id": "pNtTiywlwVYC"
   },
   "outputs": [],
   "source": [
    "base_url = \"https://mt1.google.com/vt/lyrs=s\"\n",
    "scale = 1           # scale of 1 = 256*256 dimensional image\n",
    "\n",
    "if not os.path.exists(output_folder):\n",
    "    os.makedirs(output_folder)\n",
    "    print(f\"Created the folder: {output_folder}\")\n",
    "else:\n",
    "    print(f\"The folder already exists: {output_folder}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tAzJ_LGSwVVi",
   "metadata": {
    "id": "tAzJ_LGSwVVi"
   },
   "outputs": [],
   "source": [
    "download_map_tiles(base_url, output_folder, zoom_level, scale)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6XJeWZ1Mm7r4",
   "metadata": {
    "id": "6XJeWZ1Mm7r4"
   },
   "source": [
    "# SAVE PREDICTIONS IN CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "HmWdB5vbzP55",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1737461841167,
     "user": {
      "displayName": "ICTD IITD",
      "userId": "11419946949516230456"
     },
     "user_tz": -330
    },
    "id": "HmWdB5vbzP55",
    "outputId": "bcdd60cf-321e-4995-f846-47dca0b6d759"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/drive/MyDrive/Pond/YoLoV11/Wells'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nK7MUjry2rUX",
   "metadata": {
    "id": "nK7MUjry2rUX"
   },
   "source": [
    "Initialize model and parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ltVrlZJqYwmi",
   "metadata": {
    "id": "ltVrlZJqYwmi"
   },
   "outputs": [],
   "source": [
    "\n",
    "model_path = \"Wells_results/100epochs_noAlbumentations/weights/best.pt\"\n",
    "model_path = os.path.join(pwd, model_path)\n",
    "\n",
    "image_dir = \"/content/drive/MyDrive/Pond/Data_Download/Final/Zoom18/Pindwara\"\n",
    "#image_dir = os.path.join(pwd, image_dir)\n",
    "\n",
    "csv_file = \"predictions_Pindwara_100epochs_noAlbumentations.csv\"\n",
    "\n",
    "zoom  = 18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "YPlNd6oRiIOU",
   "metadata": {
    "id": "YPlNd6oRiIOU"
   },
   "outputs": [],
   "source": [
    "# Define class-specific confidence thresholds\n",
    "conf_thresholds = {\n",
    "    'Wells': 0.71,\n",
    "}\n",
    "\n",
    "# Class names (ensure these match the order used in your model training)\n",
    "class_names = [\n",
    "    'Wells',\n",
    "\n",
    "]\n",
    "\n",
    "# Mapping of class names to abbreviations\n",
    "class_abbreviations = {\n",
    "    'Wells': 'W',\n",
    "\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0-jdfCwYnUxQ",
   "metadata": {
    "id": "0-jdfCwYnUxQ"
   },
   "source": [
    "Load the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "CFxzVndBnrFh",
   "metadata": {
    "id": "CFxzVndBnrFh"
   },
   "outputs": [],
   "source": [
    "my_new_model = YOLO(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NOuYYLEtoIFU",
   "metadata": {
    "id": "NOuYYLEtoIFU"
   },
   "source": [
    "FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "jS-Ny2QNnsfE",
   "metadata": {
    "id": "jS-Ny2QNnsfE"
   },
   "outputs": [],
   "source": [
    "def process_image(image_path, conf_thresholds):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(f\"Error: Unable to load image {image_path}\")\n",
    "        return None, None, None, None, None\n",
    "\n",
    "    results = my_new_model.predict(img)\n",
    "\n",
    "    polygons = []\n",
    "    pred_classes = []\n",
    "    conf_scores = []\n",
    "\n",
    "    if results[0].masks is not None:\n",
    "        for i, (polygon, cls, conf) in enumerate(zip(results[0].masks.xy, results[0].boxes.cls.cpu().numpy(), results[0].boxes.conf.cpu().numpy())):\n",
    "            class_name = class_names[int(cls)]\n",
    "            if conf >= conf_thresholds[class_name]:\n",
    "                polygons.append(polygon)\n",
    "                pred_classes.append(class_name)\n",
    "                conf_scores.append(conf)\n",
    "\n",
    "    return image_path, len(polygons), polygons, pred_classes, conf_scores\n",
    "\n",
    "def extract_xtile_ytile(image_path):\n",
    "    try:\n",
    "        basename = os.path.basename(image_path)\n",
    "        parts = basename.split('_')\n",
    "        if len(parts) >= 4:\n",
    "            xtile = int(parts[2])\n",
    "            ytile = int(parts[3].split('.')[0].split()[0])\n",
    "            return xtile, ytile\n",
    "        else:\n",
    "            raise ValueError(\"Filename does not contain valid tile coordinates\")\n",
    "    except Exception as e:\n",
    "        raise ValueError(f\"Filename {image_path} does not contain valid tile coordinates: {e}\")\n",
    "\n",
    "\n",
    "def tile_corners_to_latlon(xtile, ytile, zoom):\n",
    "    n = 2.0 ** zoom\n",
    "    lon_deg = xtile / n * 360.0 - 180.0\n",
    "    lat_rad_nw = math.atan(math.sinh(math.pi * (1 - 2 * (ytile / n))))\n",
    "    lat_deg_nw = math.degrees(lat_rad_nw)\n",
    "\n",
    "    lat_rad_se = math.atan(math.sinh(math.pi * (1 - 2 * ((ytile + 1) / n))))\n",
    "    lat_deg_se = math.degrees(lat_rad_se)\n",
    "\n",
    "    lat_deg_nw = max(min(lat_deg_nw, 85.0511), -85.0511)\n",
    "    lat_deg_se = max(min(lat_deg_se, 85.0511), -85.0511)\n",
    "\n",
    "    top_left = (lat_deg_nw, lon_deg)\n",
    "    top_right = (lat_deg_nw, lon_deg + (360.0 / n))\n",
    "    bottom_right = (lat_deg_se, lon_deg + (360.0 / n))\n",
    "    bottom_left = (lat_deg_se, lon_deg)\n",
    "\n",
    "    return top_left, top_right, bottom_left, bottom_right\n",
    "\n",
    "def calculate_tile_center(top_left, top_right, bottom_left, bottom_right):\n",
    "    center_lat = (top_left[0] + bottom_left[0]) / 2\n",
    "    center_lon = (top_left[1] + top_right[1]) / 2\n",
    "    return (center_lat, center_lon)\n",
    "\n",
    "def visualize_polygons(image_path, polygons, pred_classes, conf_scores):\n",
    "    img = cv2.imread(image_path)\n",
    "    if img is None:\n",
    "        print(f\"Error: Unable to load image {image_path}\")\n",
    "        return\n",
    "\n",
    "    if len(polygons) == 0:\n",
    "        print(f\"No predictions for image {image_path}, not saving.\")\n",
    "        return\n",
    "\n",
    "    for i, polygon in enumerate(polygons):\n",
    "        polygon = np.array(polygon, dtype=np.int32)\n",
    "        polygon = polygon.reshape((-1, 1, 2))\n",
    "        cv2.polylines(img, [polygon], isClosed=True, color=(0, 255, 0), thickness=2)\n",
    "\n",
    "        # Calculate the centroid of the polygon for placing the text\n",
    "        M = cv2.moments(polygon)\n",
    "        if M[\"m00\"] != 0:\n",
    "            cX = int(M[\"m10\"] / M[\"m00\"])\n",
    "            cY = int(M[\"m01\"] / M[\"m00\"])\n",
    "        else:\n",
    "            cX, cY = polygon[0][0]\n",
    "\n",
    "        # Put class abbreviation and confidence score text on the image\n",
    "        class_abbr = class_abbreviations[pred_classes[i]]\n",
    "        conf_text = f\"{class_abbr}: {conf_scores[i]:.2f}\"\n",
    "        cv2.putText(img, conf_text, (cX, cY), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 0, 255), 2)\n",
    "\n",
    "    output_path = os.path.join(annotated_images_dir, os.path.basename(image_path))\n",
    "    cv2.imwrite(output_path, img)\n",
    "    print(f\"Annotated image saved to {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "NRIKTsyUoLiE",
   "metadata": {
    "id": "NRIKTsyUoLiE"
   },
   "source": [
    "Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "zNs0fFuloLAC",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "executionInfo": {
     "elapsed": 120370,
     "status": "error",
     "timestamp": 1737462175535,
     "user": {
      "displayName": "ICTD IITD",
      "userId": "11419946949516230456"
     },
     "user_tz": -330
    },
    "id": "zNs0fFuloLAC",
    "outputId": "dafb84b6-9a17-4bd5-81d2-ab43cafcb8e2"
   },
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "[Errno 5] Input/output error: '/content/drive/MyDrive/Pond/Data_Download/Final/Zoom18/Pindwara'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-17-2228334650f6>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimage_files\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mf\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m: [Errno 5] Input/output error: '/content/drive/MyDrive/Pond/Data_Download/Final/Zoom18/Pindwara'"
     ]
    }
   ],
   "source": [
    "image_files = [os.path.join(image_dir, f) for f in os.listdir(image_dir) if os.path.isfile(os.path.join(image_dir, f))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tI6EcvUNbkLO",
   "metadata": {
    "id": "tI6EcvUNbkLO"
   },
   "outputs": [],
   "source": [
    "# Start timing\n",
    "start_time = time.time()\n",
    "\n",
    "max_vertices = 0\n",
    "for image_path in image_files:\n",
    "    _, _, polygons, _, _ = process_image(image_path, conf_thresholds)\n",
    "    for polygon in polygons:\n",
    "        max_vertices = max(max_vertices, len(polygon))\n",
    "\n",
    "with open(csv_file, 'w', newline='') as csvfile:\n",
    "    csvwriter = csv.writer(csvfile)\n",
    "    header = [\"Image Path\", \"Predicted Class\", \"Center Latitude\", \"Center Longitude\",\n",
    "              \"Top Left Latitude\", \"Top Left Longitude\", \"Top Right Latitude\", \"Top Right Longitude\",\n",
    "              \"Bottom Left Latitude\", \"Bottom Left Longitude\", \"Bottom Right Latitude\", \"Bottom Right Longitude\"]\n",
    "    for i in range(1, max_vertices + 1):\n",
    "        header.extend([f'X_{i}', f'Y_{i}'])\n",
    "    csvwriter.writerow(header)\n",
    "\n",
    "    for image_path in image_files:\n",
    "        try:\n",
    "            image_path, num_polygons, polygons, pred_classes, _ = process_image(image_path, conf_thresholds)\n",
    "            if image_path is None:\n",
    "                continue\n",
    "\n",
    "            xtile, ytile = extract_xtile_ytile(image_path)\n",
    "            top_left, top_right, bottom_left, bottom_right = tile_corners_to_latlon(xtile, ytile, zoom)\n",
    "            latitude, longitude = calculate_tile_center(top_left, top_right, bottom_left, bottom_right)\n",
    "\n",
    "            for pred_class, polygon in zip(pred_classes, polygons):\n",
    "                row = [image_path, pred_class, latitude, longitude, top_left[0], top_left[1], top_right[0], top_right[1],\n",
    "                       bottom_left[0], bottom_left[1], bottom_right[0], bottom_right[1]]\n",
    "                for point in polygon:\n",
    "                    row.extend([point[0], point[1]])\n",
    "                csvwriter.writerow(row)\n",
    "        except ValueError as e:\n",
    "            print(e)\n",
    "            continue\n",
    "\n",
    "# End timing\n",
    "end_time = time.time()\n",
    "\n",
    "# Print the time taken\n",
    "time_taken = end_time - start_time\n",
    "print(f\"CSV file '{csv_file}' saved successfully.\")\n",
    "print(f\"Time taken to complete: {time_taken:.2f} seconds.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7vBqqRJWDOxu",
   "metadata": {
    "id": "7vBqqRJWDOxu"
   },
   "source": [
    "# Convert to Geometry\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cACq_MSIDkOP",
   "metadata": {
    "id": "cACq_MSIDkOP"
   },
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bP5D_IBkdIsm",
   "metadata": {
    "id": "bP5D_IBkdIsm"
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "ZOOM_LEVEL = 18\n",
    "EARTH_CIRCUMFERENCE_DEGREES = 360  # degrees\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "mMMncfFKDVTL",
   "metadata": {
    "id": "mMMncfFKDVTL"
   },
   "outputs": [],
   "source": [
    "# Load the CSV file\n",
    "df = pd.read_csv(\"predictions_Pindwara_100epochs_noAlbumentations.csv\")\n",
    "\n",
    "df.rename(columns={'Predicted Class': 'Class'}, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "am5cwkEADgyr",
   "metadata": {
    "id": "am5cwkEADgyr"
   },
   "outputs": [],
   "source": [
    "from shapely.geometry import Polygon, Point\n",
    "\n",
    "def degrees_per_pixel(zoom):\n",
    "    total_pixels = 256 * (2 ** zoom)\n",
    "    degrees_per_pixel = EARTH_CIRCUMFERENCE_DEGREES / total_pixels\n",
    "    return degrees_per_pixel\n",
    "\n",
    "def pixel_to_geo(x, y, lat_top_left, lon_top_left, lat_bottom_right, lon_bottom_right, img_width, img_height):\n",
    "    lon_range = lon_bottom_right - lon_top_left\n",
    "    lat_range = lat_top_left - lat_bottom_right  # Note: latitude decreases as you go south\n",
    "    lon = lon_top_left + (x / img_width) * lon_range\n",
    "    lat = lat_top_left - (y / img_height) * lat_range  # y increases downward in image coordinates\n",
    "    return lon, lat\n",
    "\n",
    "# Initialize an empty list to store GeoJSON features\n",
    "geojson_features = []\n",
    "\n",
    "# Iterate over each row in the dataframe\n",
    "for index, row in df.iterrows():\n",
    "    # Extract bounding coordinates of the image tile\n",
    "    lat_top_left = row['Top Left Latitude']\n",
    "    lon_top_left = row['Top Left Longitude']\n",
    "    lat_bottom_right = row['Bottom Right Latitude']\n",
    "    lon_bottom_right = row['Bottom Right Longitude']\n",
    "\n",
    "    tile_width, tile_height = 256, 256\n",
    "\n",
    "    # Initialize an empty list to store coordinates of the current object\n",
    "    object_coords = []\n",
    "\n",
    "    for i in range(1, 8759):  # Adjust this range according to your data\n",
    "        x_col = f'X_{i}'\n",
    "        y_col = f'Y_{i}'\n",
    "        if x_col in row and y_col in row:\n",
    "            x = row[x_col]\n",
    "            y = row[y_col]\n",
    "            if pd.notna(x) and pd.notna(y):\n",
    "                # Convert pixel coordinates to geographic coordinates\n",
    "                lon, lat = pixel_to_geo(x, y, lat_top_left, lon_top_left, lat_bottom_right, lon_bottom_right, tile_width, tile_height)\n",
    "                if np.isfinite(lon) and np.isfinite(lat):\n",
    "                    object_coords.append((lon, lat))\n",
    "\n",
    "        # If it's the end of the coordinates or NaN is encountered, calculate the center\n",
    "        if pd.isna(x) or pd.isna(y) or i == 8758:\n",
    "            if object_coords:  # If there are valid coordinates, compute the center\n",
    "                # Calculate the centroid\n",
    "                centroid_lon = np.mean([coord[0] for coord in object_coords])\n",
    "                centroid_lat = np.mean([coord[1] for coord in object_coords])\n",
    "                centroid = Point(centroid_lon, centroid_lat)\n",
    "\n",
    "                # Create the GeoJSON feature for the point\n",
    "                feature = {\n",
    "                    \"type\": \"Feature\",\n",
    "                    \"geometry\": centroid,\n",
    "                    \"properties\": {\n",
    "                        \"Class\": row['Class']\n",
    "                    }\n",
    "                }\n",
    "                geojson_features.append(feature)\n",
    "            object_coords = []\n",
    "\n",
    "# Extract geometries and properties for GeoDataFrame\n",
    "geometries = [feature['geometry'] for feature in geojson_features]\n",
    "properties = [feature['properties'] for feature in geojson_features]\n",
    "\n",
    "# Create a GeoDataFrame using the geometries and properties\n",
    "gdf_final = gpd.GeoDataFrame(properties, geometry=geometries, crs=\"EPSG:4326\")\n",
    "\n",
    "# Transform the GeoDataFrame to EPSG:3857 (Web Mercator)\n",
    "gdf_final = gdf_final.to_crs(epsg=3857)\n",
    "\n",
    "# Save the GeoDataFrame as a shapefile\n",
    "gdf_final.to_file('/content/drive/MyDrive/Pond/YoLoV11/Wells/predictions_Boipariguda_100epochs_noAlbumentations3.0.shp')\n",
    "\n",
    "\n",
    "\n",
    "# Optional: Print the first 5 rows of the GeoDataFrame to verify\n",
    "print(gdf_final.head())\n",
    "\n",
    "\n",
    "print(degrees_per_pixel(17))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "w3S61UoOERRO",
   "metadata": {
    "colab": {
     "background_save": true
    },
    "id": "w3S61UoOERRO"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "4yvyzdtTw1_O",
    "XjBlPtqdw_R1",
    "cZPWBJ87xOn6",
    "11a13c2e",
    "Ne9xDjh8DI1Z"
   ],
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
